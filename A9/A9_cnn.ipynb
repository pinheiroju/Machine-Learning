{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS549 Machine Learning \n",
    "# Assignment 9: Convolutional Neural Network  for image classification - Irfan Khan\n",
    "\n",
    "\n",
    "**Total points: 10**\n",
    "\n",
    "In this assignment, you will implement a fully functioning ConvNet model using PyTorch. You will use the model to conduct image classification on the MNIST dataset (handwritten digits). https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "<img src='A9image0.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For repeatability among all students and runs, set random seed to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for Python's random module\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "# Set the seed for PyTorch\n",
    "torch_seed = 42\n",
    "torch.manual_seed(torch_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data. Split into Training Data and Test data and create dataloaders for each.\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "print ('train_size', train_size)\n",
    "\n",
    "test_size = len(test_data)\n",
    "\n",
    "print ('test_size', test_size)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data,batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "train_size 60000<br>\n",
    "test_size 10000\n",
    "\n",
    "\n",
    "# Note:\n",
    "\n",
    "The first time you run this cell, a data folder will get created and you will progress indication for that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Visualize the first image in the batch\n",
    "    plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {labels[0]}\")\n",
    "    plt.show()\n",
    "    break  # Break after visualizing the first image in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "<img src='A9image1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ConvNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # Input channels (1 for grayscale), output channels (6 filters), kernel size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # Adjust based on input size after conv2. \n",
    "        #Implicit that the pooling layer is also applied after the 2nd Conv Layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # Output: 10 class probabilities (0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)  # Flatten for FC layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.log_softmax(self.fc3(x), dim=1)  # Log Softmax for better numerical stability\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an instance of the class\n",
    "\n",
    "Define the loss criterion - cross entropy loss and use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier()  # Create an instance of the defined model class\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "**4 points **\n",
    "\n",
    "Train the ConvNet over 10 epochs and print the loss once per epoch for the 938th batch\n",
    ". There are 60000 training data samples with 64 in each batch, so there will be $\\left \\lceil 60000/64\\right \\rceil =$938 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train loop\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass\n",
    "        #Start your code\n",
    "        \n",
    "        #End your Code\n",
    "        \n",
    "        # Backpropagation\n",
    "        \n",
    "        #Start your code\n",
    "        \n",
    "        #End your Code\n",
    "\n",
    "        # Update weights in accordance with optimizer\n",
    "        #Start your code\n",
    "        \n",
    "        #End your code\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        if (i==937):\n",
    "            print('[%d] loss: %.3f' %\n",
    "                  (epoch + 1, running_loss/938))\n",
    "            running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "[1] loss: 0.243<br>\n",
    "[2] loss: 0.075<br>\n",
    "[3] loss: 0.052<br>\n",
    "[4] loss: 0.041<br>\n",
    "[5] loss: 0.032<br>\n",
    "[6] loss: 0.027<br>\n",
    "[7] loss: 0.023<br>\n",
    "[8] loss: 0.020<br>\n",
    "[9] loss: 0.019<br>\n",
    "[10] loss: 0.016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Calculate Loss for the Test data on the Trained Conv Net & Collect Outputs for Use in Next Cell\n",
    "\n",
    "**3 Points ****\n",
    "\n",
    "Calculate Avg Loss for 10000 samples of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "concatenated_outputs = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    with torch.no_grad():  \n",
    "        #begin your code, calculate loss in \"loss\"\n",
    "        \n",
    "        \n",
    "        #End your code\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        #if i % 1000 == 999:  # Print every 1000 samples\n",
    "print('[%d] loss: %.3f' % (i + 1, running_loss / 10000))\n",
    "           \n",
    "final_output = torch.cat(concatenated_outputs, dim=0)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Output\n",
    "\n",
    "[10000] loss: 0.041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Test the Trained Conv Net \n",
    "\n",
    "Test the Trained Conv Net on three random samples in the test data to see if the prediction is correct!\n",
    "\n",
    "**3 points***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_seed = 5#Don't change the random seed\n",
    "random.seed(random_seed)\n",
    "# Randomly choose three images\n",
    "random_indices = random.sample(range(len(test_loader)), 3)\n",
    "print ('random_indices',random_indices)\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data \n",
    "    for j in random_indices:\n",
    "        if (i==j):\n",
    "            image_data = inputs\n",
    "            label = labels\n",
    "            #Start your code, first obtain class probabilities using torch.nn.functional.softmax from logits stored in final_output in the previous cell. Then use torch.argmax to get the predicted class.             \n",
    "            \n",
    "            #End your code\n",
    "            print(f\"Image at index {i} - Predicted Label: {prediction}\")\n",
    "            plt.imshow(image_data.squeeze(), cmap='gray')\n",
    "            plt.title(f\"Label: {label}\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "<img src='A9image2.png'>\n",
    "<img src='A9image3.png'>\n",
    "<img src='A9image4.png'>\n",
    "<img src='A9image5.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25f78cd986e649f5a1fa57f7be9a497a8fd91952316ec3e436af56ac9acfc630"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
